{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ccb289e",
      "metadata": {
        "id": "9ccb289e"
      },
      "source": [
        "# Proyecto 1 - Análitica de textos - Etapa 1\n",
        "\n",
        "## Integrantes\n",
        "- Carlos Vargas - 202220064\n",
        "- Silvana Echeverry - 202310470\n",
        "- David Mora - 202226269"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347067fe",
      "metadata": {
        "id": "347067fe"
      },
      "source": [
        "El objetivo del proyecto es construir un modelo de aprendizaje supervisado de clasificación de texto. Se espera que dado un nuevo texto de opinión, el modelo debe predecir automáticamente a cuál ODS pertenece. No es una variable binaria sino multiclase (1,3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2514496",
      "metadata": {
        "id": "e2514496"
      },
      "source": [
        "# 2. Entendimiento y preparación de los Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f9eb78",
      "metadata": {
        "id": "89f9eb78"
      },
      "source": [
        "## Entendimiento - Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e44c28e",
      "metadata": {
        "id": "0e44c28e"
      },
      "outputs": [],
      "source": [
        "# Manejo de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocesamiento\n",
        "import re, unicodedata\n",
        "import spacy  # lematización en español\n",
        "\n",
        "# Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Vectorización\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Split de train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Modelos\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Métricas y evaluación\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dbf9c36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dbf9c36",
        "outputId": "8542182e-71b0-4ad9-ce0e-7e3721946502"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download es_core_news_sm\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f07dfec",
      "metadata": {
        "id": "1f07dfec"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('Datos_proyecto.xlsx')\n",
        "#print(data.head())\n",
        "#data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf36606",
      "metadata": {
        "id": "fbf36606"
      },
      "source": [
        "Revisar como estan distribuidos nuestros datos:\n",
        "\n",
        "1. Contar cuantos labels hay, lo cual nos confirma que tenemos, para confirmar si tenemos desbalanceo o balanceo en nuestras clases\n",
        "- 4 1025 (Calidad de vida)\n",
        "-  3 894 (salud)\n",
        "- 1 505 (educación)\n",
        "2. Ver la proporción que representa cada clase con respecto al total de los datos.\n",
        "- 4 42%\n",
        "- 3 36%\n",
        "- 1 20% menor representación\n",
        "el label 4 y 3 estan mas parejas\n",
        "\n",
        "3. Mostrar la grafica\n",
        "- con la grafica podemos ver que nuestras label tienen un leve desbalance pero consideramos que podemos seguir trabajando\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc24250",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "1fc24250",
        "outputId": "86401a7d-c365-491b-a90f-3b3ed3778065"
      },
      "outputs": [],
      "source": [
        "# Conteo de ejemplos por clase\n",
        "print(data['labels'].value_counts())\n",
        "\n",
        "# Proporción de ejemplos por clase\n",
        "print(data['labels'].value_counts(normalize=True))\n",
        "\n",
        "sns.countplot(x='labels', data=data, palette=\"Set2\")\n",
        "plt.title(\"Distribución de clases (labels)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c0745a0",
      "metadata": {
        "id": "7c0745a0"
      },
      "source": [
        "Con esto verificamos las longitudes de los textos y las palabras antes de limpiarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e272b9a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e272b9a2",
        "outputId": "c233f1ee-3ee7-4a6b-e272-984f76592744"
      },
      "outputs": [],
      "source": [
        "data_copy = data.copy()\n",
        "data_copy['conteo'] = [len(x) for x in data_copy['textos']]\n",
        "data_copy['max'] = [[max([len(x) for x in i.split(' ')])][0] for i in data_copy['textos']]\n",
        "data_copy['min'] = [[min([len(x) for x in i.split(' ')])][0] for i in data_copy['textos']]\n",
        "data_copy['mean'] = [np.mean([len(x) for x in i.split(' ')]) for i in data_copy['textos']]\n",
        "\n",
        "data_copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c263f8b2",
      "metadata": {
        "id": "c263f8b2"
      },
      "source": [
        "## Procesamiento de los Datos\n",
        "#### Limpieza de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c09bdc",
      "metadata": {
        "id": "f3c09bdc"
      },
      "source": [
        "En la parte de limpieza de los datos vamos a dejar todo en minusculas, eliminar caracteres especiales, puntuación, nonASCII characters y stopwords  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22fce2e",
      "metadata": {
        "id": "e22fce2e"
      },
      "outputs": [],
      "source": [
        "def limpieza_y_lematizacion(texto: str) -> str:\n",
        "    #minúsculas\n",
        "    texto = str(texto).lower()\n",
        "\n",
        "    #acentos / non-ASCII\n",
        "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto)\n",
        "                    if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "    # puntuación y caracteres especiales\n",
        "    texto = re.sub(r'[^a-z0-9\\s]', ' ', texto)\n",
        "\n",
        "    # procesar con spaCy y devolver lemas sin stopwords ni puntuación\n",
        "    doc = nlp(texto)\n",
        "    lemas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "    # Reconstruir texto limpio\n",
        "    return \" \".join(lemas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a681da9",
      "metadata": {
        "id": "2a681da9"
      },
      "source": [
        "#### Tokenización\n",
        "Vamos a dividir en frases u oraciones en palabras Con el fin de desglozar las palabras correctamente para el posterior análisis. Como en español no hay contractions no aplicamos esa función. Sin embargo, tenemos en cuenta también las palabras compuestas como niños(as) estas las separamos en tokens diferentes, ademas podemos eliminar comillas, parentesis y guiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90a7586f",
      "metadata": {
        "id": "90a7586f"
      },
      "outputs": [],
      "source": [
        "def tokenizacion(texto: str):\n",
        "    tokens = re.findall(r\"[a-zA-ZáéíóúÁÉÍÓÚñÑüÜ0-9]+\", texto)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9115c43",
      "metadata": {
        "id": "c9115c43"
      },
      "source": [
        "#### Normalizacion\n",
        "Aqui eliminamos las stopwords.\n",
        "- Se utilizo chat gpt para que generara la lista con las spanish stopwords que queremos eliminar, ya que generalmente las librerias estan en ingles y no reconocen las stopwords en español"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b208d0ae",
      "metadata": {
        "id": "b208d0ae"
      },
      "outputs": [],
      "source": [
        "spanish_stopwords = [\n",
        "    'a', 'acá', 'ahí', 'ajena', 'ajenas', 'ajeno', 'ajenos', 'al', 'algo', 'algún',\n",
        "    'alguna', 'algunas', 'alguno', 'algunos', 'allá', 'allí', 'ambos', 'ante',\n",
        "    'antes', 'aquel', 'aquella', 'aquellas', 'aquello', 'aquellos', 'aquí',\n",
        "    'arriba', 'así', 'atrás', 'aun', 'aunque', 'bajo', 'bastante', 'bien', 'cabe',\n",
        "    'cada', 'casi', 'cierta', 'ciertas', 'cierto', 'ciertos', 'como', 'con',\n",
        "    'conmigo', 'contigo', 'contra', 'cual', 'cuales', 'cualquier', 'cualquiera',\n",
        "    'cualquieras', 'cuan', 'cuando', 'cuanta', 'cuantas', 'cuanto', 'cuantos',\n",
        "    'de', 'dejar', 'del', 'demás', 'demasiada', 'demasiadas', 'demasiado',\n",
        "    'demasiados', 'dentro', 'desde', 'donde', 'dos', 'el', 'él', 'ella', 'ellas',\n",
        "    'ello', 'ellos', 'empleáis', 'emplean', 'emplear', 'empleas', 'empleo', 'en',\n",
        "    'encima', 'entonces', 'entre', 'era', 'eramos', 'eran', 'eras', 'eres', 'es',\n",
        "    'esa', 'esas', 'ese', 'eso', 'esos', 'esta', 'estaba', 'estado', 'estáis',\n",
        "    'estamos', 'estan', 'estar', 'estas', 'este', 'esto', 'estos', 'etc', 'ha',\n",
        "    'hace', 'haces', 'hacéis', 'hacemos', 'hacen', 'hacer', 'hacia', 'hago',\n",
        "    'hasta', 'incluso', 'intenta', 'intentáis', 'intentamos', 'intentan',\n",
        "    'intentar', 'intentas', 'intento', 'ir', 'jamás', 'junto', 'juntos', 'la',\n",
        "    'lo', 'los', 'las', 'largo', 'más', 'me', 'menos', 'mi', 'mía', 'mías', 'mío',\n",
        "    'míos', 'mis', 'misma', 'mismas', 'mismo', 'mismos', 'modo', 'mucha', 'muchas',\n",
        "    'muchísima', 'muchísimas', 'muchísimo', 'muchísimos', 'mucho', 'muchos', 'muy',\n",
        "    'nada', 'ni', 'ninguna', 'ningunas', 'ninguno', 'ningunos', 'no', 'nos',\n",
        "    'nosotras', 'nosotros', 'nuestra', 'nuestras', 'nuestro', 'nuestros', 'nunca',\n",
        "    'os', 'otra', 'otras', 'otro', 'otros', 'para', 'parecer', 'pero', 'poca',\n",
        "    'pocas', 'poco', 'pocos', 'podeis', 'podemos', 'poder', 'podría', 'podríais',\n",
        "    'podríamos', 'podrían', 'por', 'porque', 'primero', 'puede', 'pueden', 'puedo',\n",
        "    'pues', 'que', 'querer', 'quien', 'quienes', 'quienesquiera', 'quienquiera',\n",
        "    'quizá', 'quizás', 'sabe', 'sabes', 'saben', 'sabéis', 'sabemos', 'saber',\n",
        "    'se', 'según', 'ser', 'si', 'sí', 'siendo', 'sin', 'sino', 'so', 'sobre',\n",
        "    'sois', 'solamente', 'solo', 'somos', 'soy', 'su', 'sus', 'suya', 'suyas',\n",
        "    'suyo', 'suyos', 'tal', 'tales', 'también', 'tampoco', 'tan', 'tanta',\n",
        "    'tantas', 'tanto', 'tantos', 'te', 'teneis', 'tenemos', 'tener', 'tengo',\n",
        "    'ti', 'tiempo', 'tiene', 'tienen', 'toda', 'todas', 'todo', 'todos', 'tras',\n",
        "    'tu', 'tus', 'tuya', 'tuyas', 'tuyo', 'tuyos', 'un', 'una', 'unas', 'uno',\n",
        "    'unos', 'usa', 'usáis', 'usamos', 'usan', 'usar', 'usas', 'uso', 'usted',\n",
        "    'ustedes', 'va', 'vais', 'valor', 'vamos', 'van', 'varias', 'varios', 'vaya',\n",
        "    'verdad', 'verdadera', 'vosotras', 'vosotros', 'voy', 'vuestra', 'vuestras',\n",
        "    'vuestro', 'vuestros', 'y', 'ya'\n",
        "]\n",
        "def normalizacion(tokens):\n",
        "    return [t for t in tokens if t not in spanish_stopwords]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6417b950",
      "metadata": {
        "id": "6417b950"
      },
      "source": [
        "Juntar todo lo que hicimos, en una copia de nuestros datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5664a7f3",
      "metadata": {
        "id": "5664a7f3"
      },
      "outputs": [],
      "source": [
        "data_copy = data.copy()\n",
        "\n",
        "# Aplicar las funciones de preprocesamiento\n",
        "data_copy['textos_clean'] = data_copy['textos'].apply(limpieza_y_lematizacion)\n",
        "data_copy['tokens'] = data_copy['textos_clean'].apply(tokenizacion)\n",
        "data_copy['tokens_norm'] = data_copy['tokens'].apply(normalizacion)\n",
        "\n",
        "\n",
        "# print(data_copy[['tokens_norm','labels']].head(3))\n",
        "#data_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd6ef62",
      "metadata": {
        "id": "ccd6ef62"
      },
      "outputs": [],
      "source": [
        "# exportar a excel para saber como nos esta quedando\n",
        "#data_copy[['textos','tokens_norm']].to_excel(\"tokens_norm.xlsx\", index=False)\n",
        "#data_copy[['textos','tokens_norm']].to_excel(\"tokens_norm_lema.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79beab82",
      "metadata": {
        "id": "79beab82"
      },
      "source": [
        "#### Selección de campos y vectorizacion\n",
        "Esto nos permite traducir nuestras palabras ya tokenizadas en numeros ya que los modelos que vamos a usar no nos funcionan con palabras sino con numeros.\n",
        "Basicamente lo que vamos a hacer es:\n",
        "1. Selección de campos: separar que columna es la variable predictora y cual es la variable objetivo (lo organiza para que sklearn lo entienda)\n",
        "2. Vectorización: convierte cada texto en un vector indicando cuántas veces aparece cada palabra.\n",
        "3. TfidfVectorizer: pondera cada palabra por su importancia en el documento y en el corpus. penaliza palabras que no nos esten aportantando tanto y favore a las que si.\n",
        "4. Construcción de la matriz: construimos una matriz de documentos vs vocabulario,\n",
        "- Cada fila = un documento (texto del dataset).\n",
        "- Cada columna = una palabra del vocabulario.\n",
        "- El valor = la frecuencia o el peso TF-IDF de esa palabra en ese documento.\n",
        "\n",
        "Entonces, esto va a traducir el texto en números para que los modelos puedan trabajar. Además, esta matriz sirve para identificar palabras relevantes en cada clase, lo cual necesitamos para justificar cómo los textos se relacionan con los ODS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d22f88a",
      "metadata": {
        "id": "2d22f88a"
      },
      "source": [
        "Hacemos la selección de campos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c50d9e13",
      "metadata": {
        "id": "c50d9e13"
      },
      "outputs": [],
      "source": [
        "data_ready = data_copy.copy()\n",
        "\n",
        "data_ready['words'] = data_ready['tokens_norm'].apply(lambda xs: ' '.join(map(str, xs)))\n",
        "\n",
        "X_data = data_ready['words']\n",
        "y_data = data_ready['labels'].astype(int)\n",
        "\n",
        "#print(X_data.head(2))\n",
        "#print(y_data.value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3639b54d",
      "metadata": {
        "id": "3639b54d"
      },
      "source": [
        "Vectorización"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adee90d0",
      "metadata": {
        "id": "adee90d0"
      },
      "source": [
        "Presencia binaria (Bag-of-Words binario): No importa cuántas veces aparezca una palabra en el texto. Solo se indica si la palabra está presente (1) o ausente (0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ff2d4e",
      "metadata": {
        "id": "98ff2d4e"
      },
      "outputs": [],
      "source": [
        "dummy = CountVectorizer(binary=True)\n",
        "X_dummy = dummy.fit_transform(X_data)\n",
        "\n",
        "#print(\"BoW binario:\", X_dummy.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e02537",
      "metadata": {
        "id": "12e02537"
      },
      "source": [
        "Conteo (Bag-of-Words con frecuencias): Cada palabra del vocabulario se representa con la cantidad de veces que aparece en el documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00fec6b",
      "metadata": {
        "id": "f00fec6b"
      },
      "outputs": [],
      "source": [
        "count = CountVectorizer()\n",
        "X_count = count.fit_transform(X_data)\n",
        "#print(\"BoW conteo:\", X_count.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d65825",
      "metadata": {
        "id": "d0d65825"
      },
      "source": [
        "TF–IDF: toma lo anterior y le asigna un peso para la matriz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb45c36",
      "metadata": {
        "id": "7fb45c36"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    min_df=5,        # ignora términos muy raros (<5 documentos)\n",
        "    max_df=0.9,      # ignora términos demasiado comunes (>90% de documentos)\n",
        "    lowercase=False,      # ya está en minúsculas\n",
        "    strip_accents=None, # se quira tildes\n",
        "    sublinear_tf=True,  #textos largos no dominen\n",
        "    ngram_range=(1,1) # luego probamos (1,2) para bigramas como \"salud publica\"\n",
        ")\n",
        "X_tfidf = tfidf.fit_transform(X_data)\n",
        "\n",
        "#print(\"TF-IDF:\", X_tfidf.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b50cbafe",
      "metadata": {
        "id": "b50cbafe"
      },
      "source": [
        "Dvidir en data train y data test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a95b813",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a95b813",
        "outputId": "2a8cffca-5d4a-46d5-ff43-dd495b5682fc"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_data, y_data, test_size=0.2, stratify=y_data, random_state=42\n",
        ")\n",
        "\n",
        "# Ajustar TF-IDF solo con train\n",
        "tfidf = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1,1))\n",
        "Xtr = tfidf.fit_transform(X_train)\n",
        "Xte = tfidf.transform(X_test)\n",
        "\n",
        "#print(Xtr.shape, Xte.shape)\n",
        "\n",
        "print(\"Distribución train:\", np.bincount(y_train)/len(y_train))\n",
        "print(\"Distribución test :\", np.bincount(y_test)/len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f4a861",
      "metadata": {
        "id": "69f4a861"
      },
      "source": [
        "Lo anterior nos dice que\n",
        "el 20% de los textos son de la clase 1 - fin de la pobreza\n",
        "el 36% de los textos son de la clase 3 - salud y bienestar\n",
        "el 42% de los textos son de la clase 4 - educación y calidad\n",
        "\n",
        "lo mismo que nos estaba dando al inicio, lo cual indica que nuestro modelo si logro hacer el split correctamente, asegurando que verá ejemplos representativos de todas las clases en train y test."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a951c4b5",
      "metadata": {
        "id": "a951c4b5"
      },
      "source": [
        "# 3. Modelado y evaulación"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1725f9c2",
      "metadata": {
        "id": "1725f9c2"
      },
      "source": [
        "## Naive Bayes - Silvana Echeverry\n",
        "\n",
        "Como primer algoritmo vamos a utilizar Naive Bayes. Este es muy sencillo y rapido ya que se ajusta a matrices de tamaños muy grandes como la que construimos en TF-IDF. Además, nos da el indicador probabilistico ya que nos ayuda a saber cual clase es más probable en el texto. Es un algoritmo que se usa generalmente en clasificaciones de textos, ya que tiene un baseline clásico (un modelo inicial, sencillo y fácil de implementar, que sirve como punto de comparación para evaluar si los modelos más complejos realmente aportan mejoras.). Nos ayuda a entender y comparar ventajas y desventajas.\n",
        "\n",
        "##### Tipos de Naive Bayes en SKLEARN\n",
        "1. Gaussian Naive Bayes: asume que los datos (features) siguen una distribución gaussiana entonces lo hace util para datos continuos, no para textos\n",
        "2. Multinomial Naive Bayes: supone que los datos son conteos o frecuencias, lo cual lo hace ideal para Bag-of-Words y TF-IDF\n",
        "3. Complement Naive Bayes: esta diseñado para datos desbalanceados,\n",
        "4. Bernoulli Naive Bayes: Usa variables binarias (0/1 si una palabra aparece o no), util con BoW binario, no tanto con TF-IDF.\n",
        "5. Categorical Naive Bayes: Diseñado para features categóricas discretas, No sirve para TF-IDF ni BoW porque no sirve para textos\n",
        "6. Out-of-core naive Bayes model fitting: Variante de MultinomialNB o BernoulliNB para entrenar en datasets enormes que no caben en memoria.\n",
        "\n",
        "A partir de estos tipos el mejor que nos funcionaria en este caso es Multinomial Naive Bayes y Complement Naive Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b226a2",
      "metadata": {
        "id": "c1b226a2"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaebdc16",
      "metadata": {
        "id": "aaebdc16"
      },
      "source": [
        "Aca quiero verificar con cual alpha es mejor. que es mi hiperparámetro\n",
        "\n",
        "¿Qué es un alpha? el alpha controla cuánto “rellenamos” las probabilidades para evitar que sean cero cuando una palabra no aparece en los datos de entrenamiento de cierta clase. Sin suavizar la probabilidad  haría que cualquier texto con esa palabra jamás se clasifique.\n",
        "\n",
        "Lo que estoy haciendo es entrenar varios modelos con diferentes valores de alpha y medir el F1-macro en el conjunto de datos de prueba.\n",
        "De esa forma puedes elegir el alpha que dé mejor rendimiento en tu dataset, en lugar de aceptar ciegamente el valor por defecto\n",
        "\n",
        "Basicamente un busqueda hice la hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1231fc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1231fc9",
        "outputId": "f2aed95d-2cc8-4bbc-9a32-644e364da0da"
      },
      "outputs": [],
      "source": [
        "alphas = [0.1, 0.3, 0.5, 1.0, 2.0,100, 20, 50, 0.05, 0.7, 0.6, 0.55, 0.33, 0.2, 0.25, 0.15, 0.31, 0.35, 0.65, 0.71, 0.72, 0.69, 0.75, 0.8, 0.85]\n",
        "scores = []\n",
        "\n",
        "for a in alphas:\n",
        "    m = MultinomialNB(alpha=a, fit_prior=True)\n",
        "    m.fit(Xtr, y_train)\n",
        "    pred = m.predict(Xte)\n",
        "    f1m = f1_score(y_test, pred, average='macro')\n",
        "    scores.append((a, f1m))\n",
        "    print(f\"alpha={a:<4} -> F1-macro={f1m:.4f}\")\n",
        "\n",
        "# Mejor alpha\n",
        "best_alpha, best_f1 = max(scores, key=lambda x: x[1])\n",
        "print(f\"\\nMejor alpha: {best_alpha} (F1-macro={best_f1:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db370c0",
      "metadata": {
        "id": "6db370c0"
      },
      "source": [
        "A partir de lo anterior, nos podemos dar cuenta que el mejor alpha es 0.7 y es el que usamos en nuestro modelo multinomial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27fb32d3",
      "metadata": {
        "id": "27fb32d3"
      },
      "source": [
        "Para train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56060a85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "56060a85",
        "outputId": "487268dc-3149-4df7-a2d2-b792be1bef01"
      },
      "outputs": [],
      "source": [
        "mnb = MultinomialNB(alpha=0.7, fit_prior=True)\n",
        "mnb.fit(Xtr, y_train)\n",
        "\n",
        "y_pred_train = mnb.predict(Xtr)\n",
        "\n",
        "\n",
        "print(classification_report(y_train, y_pred_train, digits=3))\n",
        "print(\"F1-macro (train):\", f1_score(y_train, y_pred_train, average='macro'))\n",
        "print(\"Accuracy (train):\", accuracy_score(y_train, y_pred_train))\n",
        "\n",
        "# Matriz de confusión (TRAIN)\n",
        "\n",
        "cm_tr = confusion_matrix(y_train, y_pred_train, labels=mnb.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_tr, display_labels=mnb.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - MultinomialNB (TRAIN)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC y curvas ROC por clase (TRAIN)\n",
        "\n",
        "# Probabilidades por clase en TRAIN\n",
        "y_proba_tr = mnb.predict_proba(Xtr)\n",
        "\n",
        "classes = mnb.classes_\n",
        "y_train_bin = label_binarize(y_train, classes=classes)\n",
        "\n",
        "# ROC AUC (macro OVR) en TRAIN\n",
        "roc_auc_train = roc_auc_score(y_train, y_proba_tr, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TRAIN, macro OVR):\", roc_auc_train)\n",
        "\n",
        "# Curvas ROC por clase\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes):\n",
        "    fpr, tpr, _ = roc_curve(y_train_bin[:, i], y_proba_tr[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "# Línea de azar\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Azar\")\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - MultinomialNB (TRAIN)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085b49ca",
      "metadata": {
        "id": "085b49ca"
      },
      "source": [
        "para TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "760cd13f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "760cd13f",
        "outputId": "77e9d4d5-0bbf-43cb-b56e-5233bb8d5474"
      },
      "outputs": [],
      "source": [
        "y_pred_test = mnb.predict(Xte)\n",
        "\n",
        "print(classification_report(y_test, y_pred_test, digits=3))\n",
        "print(\"F1-macro (test):\", f1_score(y_test, y_pred_test, average='macro'))\n",
        "print(\"Accuracy (test):\", accuracy_score(y_test, y_pred_test))\n",
        "\n",
        "#  Matriz de confusión (TEST)\n",
        "cm_te = confusion_matrix(y_test, y_pred_test, labels=mnb.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_te, display_labels=mnb.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - MultinomialNB (TEST)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC\n",
        "y_proba_te = mnb.predict_proba(Xte)\n",
        "\n",
        "classes = mnb.classes_\n",
        "y_test_bin = label_binarize(y_test, classes=classes)\n",
        "\n",
        "# ROC AUC macro OVR\n",
        "roc_auc_test = roc_auc_score(y_test, y_proba_te, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TEST, macro OVR):\", roc_auc_test)\n",
        "\n",
        "# Curvas ROC por clase\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba_te[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - MultinomialNB (TEST)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775ec126",
      "metadata": {
        "id": "775ec126"
      },
      "source": [
        "#### Complement Naive Bayes\n",
        "\n",
        "Tiene los mismos hiperparametros entonces mantenemos el 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2ea1c5",
      "metadata": {
        "id": "fd2ea1c5"
      },
      "source": [
        "Para Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5bcebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ee5bcebe",
        "outputId": "3900b6ab-bf71-41cb-d033-c68601f30b29"
      },
      "outputs": [],
      "source": [
        "#entrenar con  train\n",
        "\n",
        "cnb = ComplementNB(alpha=0.7)\n",
        "cnb.fit(Xtr, y_train)\n",
        "\n",
        "y_pred_tr = cnb.predict(Xtr)\n",
        "\n",
        "print(classification_report(y_train, y_pred_tr, digits=3))\n",
        "print(\"F1-macro (train):\", f1_score(y_train, y_pred_tr, average='macro'))\n",
        "print(\"Accuracy (train):\", accuracy_score(y_train, y_pred_tr))\n",
        "\n",
        "#matriz de confusión\n",
        "cm_tr = confusion_matrix(y_train, y_pred_tr, labels=cnb.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_tr, display_labels=cnb.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - ComplementNB (TRAIN)\")\n",
        "plt.show()\n",
        "\n",
        "# roc auc y curvas roc por clase (train)\n",
        "y_proba_tr = cnb.predict_proba(Xtr)\n",
        "classes = cnb.classes_\n",
        "y_train_bin = label_binarize(y_train, classes=classes)\n",
        "\n",
        "roc_auc_tr = roc_auc_score(y_train, y_proba_tr, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TRAIN, macro OVR):\", roc_auc_tr)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes):\n",
        "    fpr, tpr, _ = roc_curve(y_train_bin[:, i], y_proba_tr[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "plt.plot([0,1],[0,1],\"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\"); plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - ComplementNB (TRAIN)\")\n",
        "plt.legend(loc=\"lower right\"); plt.grid(alpha=0.2); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "531d3ea1",
      "metadata": {
        "id": "531d3ea1"
      },
      "source": [
        "Para Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5323736a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5323736a",
        "outputId": "970586b9-97f9-4b03-8d9c-cdfdf7f7cf6f"
      },
      "outputs": [],
      "source": [
        "y_pred_te = cnb.predict(Xte)\n",
        "print(classification_report(y_test, y_pred_te, digits=3))\n",
        "print(\"F1-macro (test):\", f1_score(y_test, y_pred_te, average='macro'))\n",
        "print(\"Accuracy (test):\", accuracy_score(y_test, y_pred_te))\n",
        "# Matriz de confusión (TEST)\n",
        "cm_te = confusion_matrix(y_test, y_pred_te, labels=cnb.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_te, display_labels=cnb.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - ComplementNB (TEST)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC y curvas ROC por clase (TEST)\n",
        "y_proba_te = cnb.predict_proba(Xte)\n",
        "classes = cnb.classes_\n",
        "y_test_bin = label_binarize(y_test, classes=classes)\n",
        "\n",
        "roc_auc_te = roc_auc_score(y_test, y_proba_te, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TEST, macro OVR):\", roc_auc_te)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba_te[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "plt.plot([0,1],[0,1],\"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - ComplementNB (TEST)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f03e609",
      "metadata": {
        "id": "8f03e609"
      },
      "source": [
        "En conclusión, el mejor modelo es el de Complement Naive Bayes. Tiene la mejor relación/equilibrio entre train y test. El accuracy es mejor en test y esta pensando/creado para datos desbalanceados como los que trabajamos en este caso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b56e080",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b56e080",
        "outputId": "a3934e8d-20c4-4919-fd4f-db386fa2f14d"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cc4ZwBre2kbz",
      "metadata": {
        "id": "Cc4ZwBre2kbz"
      },
      "source": [
        "#Logistic Regression – David Mora\n",
        "\n",
        "Como segundo algoritmo usamos Regresión Logística. Es un modelo lineal para clasificación que aprende un peso por palabra (con TF-IDF) y produce probabilidades por clase. Es rápida, estable y suele superar el baseline cuando el vocabulario es grande.\n",
        "\n",
        "Modos en scikit-learn:\n",
        "\n",
        "1. Multinomial (multi_class='multinomial' con solver='lbfgs'): usa softmax y suele rendir mejor en texto.\n",
        "2. One-vs-Rest (OvR) (multi_class='ovr'): entrena un clasificador por clase; también funciona.\n",
        "3. Solvers: lbfgs (general) y saga (permite L1 y escala bien).\n",
        "4. class_weight: la opción balanced ayuda si hay desbalance de clases.\n",
        "\n",
        "Hiperparámetro principal:\n",
        "\n",
        "- C (inverso de la regularización):\n",
        "  - C alto → menos regularización (más ajuste al train).\n",
        "  - C bajo → más regularización (mejor generalización).\n",
        "\n",
        "- Normalmente uso penalty=L2 y aumento max_iter para asegurar convergencia.\n",
        "\n",
        "- En la vectorización conviene TF-IDF con unigramas y bigramas.\n",
        "\n",
        "Qué hice para elegir el modelo:\n",
        "Entrené varios modelos cambiando C (por ejemplo 0.5, 1, 2, 4) y comparé el F1-macro en validación y en test. También probé con y sin class_weight=balanced para mejorar el recall de la clase minoritaria. Elegí como modelo final la configuración con mejor F1-macro en test."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rwVrqoFwR2jt",
      "metadata": {
        "id": "rwVrqoFwR2jt"
      },
      "source": [
        "#Para Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69NhF8gEQXcH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "69NhF8gEQXcH",
        "outputId": "5cf4ad9c-bb81-4c98-a211-4fe420c8a06f"
      },
      "outputs": [],
      "source": [
        "# Inicializar y entrenar el modelo\n",
        "# lbfgs es una buena opción para multinomial\n",
        "# Ajustar la regularización y el parámetro C \n",
        "lr = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42, max_iter=1000)\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento (TF-IDF)\n",
        "lr.fit(Xtr, y_train)\n",
        "\n",
        "# Predicciones en TRAIN\n",
        "y_pred_train_lr = lr.predict(Xtr)\n",
        "\n",
        "# Evaluación en TRAIN\n",
        "print(\"--- Evaluación en TRAIN (Logistic Regression) ---\")\n",
        "print(classification_report(y_train, y_pred_train_lr, digits=3))\n",
        "print(\"F1-macro (train):\", f1_score(y_train, y_pred_train_lr, average='macro'))\n",
        "print(\"Accuracy (train):\", accuracy_score(y_train, y_pred_train_lr))\n",
        "\n",
        "# Matriz de confusión (TRAIN)\n",
        "cm_tr_lr = confusion_matrix(y_train, y_pred_train_lr, labels=lr.classes_)\n",
        "disp_tr_lr = ConfusionMatrixDisplay(confusion_matrix=cm_tr_lr, display_labels=lr.classes_)\n",
        "disp_tr_lr.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - Logistic Regression (TRAIN)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC y curvas ROC por clase (TRAIN)\n",
        "y_proba_tr_lr = lr.predict_proba(Xtr)\n",
        "classes_lr = lr.classes_\n",
        "y_train_bin_lr = label_binarize(y_train, classes=classes_lr)\n",
        "\n",
        "roc_auc_train_lr = roc_auc_score(y_train, y_proba_tr_lr, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TRAIN, macro OVR):\", roc_auc_train_lr)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes_lr):\n",
        "    fpr, tpr, _ = roc_curve(y_train_bin_lr[:, i], y_proba_tr_lr[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - Logistic Regression (TRAIN)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FhlgZaebwtKd",
      "metadata": {
        "id": "FhlgZaebwtKd"
      },
      "source": [
        "#Para Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512fcc14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "512fcc14",
        "outputId": "5411c942-b23c-48dc-f485-937bf530f76b"
      },
      "outputs": [],
      "source": [
        "# Predicciones en TEST\n",
        "y_pred_test_lr = lr.predict(Xte)\n",
        "\n",
        "# Evaluación en TEST\n",
        "print(\"--- Evaluación en TEST (Logistic Regression) ---\")\n",
        "print(classification_report(y_test, y_pred_test_lr, digits=3))\n",
        "print(\"F1-macro (test):\", f1_score(y_test, y_pred_test_lr, average='macro'))\n",
        "print(\"Accuracy (test):\", accuracy_score(y_test, y_pred_test_lr))\n",
        "\n",
        "# Matriz de confusión (TEST)\n",
        "cm_te_lr = confusion_matrix(y_test, y_pred_test_lr, labels=lr.classes_)\n",
        "disp_te_lr = ConfusionMatrixDisplay(confusion_matrix=cm_te_lr, display_labels=lr.classes_)\n",
        "disp_te_lr.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - Logistic Regression (TEST)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC y curvas ROC por clase (TEST)\n",
        "y_proba_te_lr = lr.predict_proba(Xte)\n",
        "classes_lr = lr.classes_\n",
        "y_test_bin_lr = label_binarize(y_test, classes=classes_lr)\n",
        "\n",
        "roc_auc_test_lr = roc_auc_score(y_test, y_proba_te_lr, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TEST, macro OVR):\", roc_auc_test_lr)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes_lr):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin_lr[:, i], y_proba_te_lr[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - Logistic Regression (TEST)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CCHLI28c8DWK",
      "metadata": {
        "id": "CCHLI28c8DWK"
      },
      "source": [
        "Elegimos un modelo de Regresión Logística para varias categorías. En las pruebas logró un resultado global cercano al 96% y ordenó muy bien qué texto va a cada categoría aproximadamente 99.7%. El error más frecuente fue confundir algunos textos de la categoría 1 con la 3; esto puede mejorar si el modelo toma en cuenta frases de dos palabras y da un poco más de peso a la categoría con menos ejemplos. Como superó a los modelos de referencia, lo dejamos como modelo final: rinde mejor y entrega probabilidades confiables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IBUSnv2f4SH2",
      "metadata": {
        "id": "IBUSnv2f4SH2"
      },
      "source": [
        "#KNN – Carlos Vargas\n",
        "\n",
        "KNN es un clasificador no paramétrico. Para predecir, busca los k documentos más parecidos al texto nuevo con TF-IDF y decide por votación. En texto funciona bien cuando usamos una medida de similitud adecuada y los vectores están normalizados.\n",
        "\n",
        "Modos en scikit-learn:\n",
        "\n",
        "1. n_neighbors (k): número de vecinos que votan.\n",
        "\n",
        "2. metric: cosine (recomendado para TF-IDF) o euclidean que es por defecto.\n",
        "\n",
        "3. weights: uniform (todos igual) o distance (más peso al vecino cercano).\n",
        "\n",
        "4. algorithm: brute (sencillo en alta dimensión); n_jobs=-1 para paralelizar.\n",
        "\n",
        "Hiperparámetros principales:\n",
        "\n",
        "k:\n",
        "- k pequeño: más varianza (sube recall de minoritarias, baja precisión).\n",
        "- k grande: más sesgo (suaviza y puede mejorar precisión global).\n",
        "\n",
        "metric:\n",
        "- cosine capta mejor la dirección del vector TF-IDF y suele rendir mejor que euclidean.\n",
        "\n",
        "weights:\n",
        "- distance ayuda cuando hay vecinos muy cercanos y otros ruidosos.\n",
        "\n",
        "Vectorización:\n",
        "Conviene TF-IDF con unigramas y bigramas.\n",
        "\n",
        "Qué hice para elegir el modelo:\n",
        "Entrené varias configuraciones cambiando k (3, 5, 7, 9, 15, 25), la métrica (cosine vs euclidean) y el esquema de pesos (uniform vs distance). Comparé el F1-macro en validación y en test, y escogí como modelo final la combinación con mejor F1-macro en test, priorizando también el recall de la clase minoritaria."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E6EkyODn4gOY",
      "metadata": {
        "id": "E6EkyODn4gOY"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yUkSVypVSw5I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yUkSVypVSw5I",
        "outputId": "f9321718-e892-4d48-d884-af4625e999af"
      },
      "outputs": [],
      "source": [
        "# Inicializar y entrenar el modelo\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5) # Numero de vecinos 5 (dio mejores resultados)\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento (TF-IDF)\n",
        "knn.fit(Xtr, y_train)\n",
        "\n",
        "# Predicciones en TRAIN\n",
        "y_pred_train_knn = knn.predict(Xtr)\n",
        "\n",
        "# Evaluación en TRAIN\n",
        "print(\"--- Evaluación en TRAIN (KNN) ---\")\n",
        "print(classification_report(y_train, y_pred_train_knn, digits=3))\n",
        "print(\"F1-macro (train):\", f1_score(y_train, y_pred_train_knn, average='macro'))\n",
        "print(\"Accuracy (train):\", accuracy_score(y_train, y_pred_train_knn))\n",
        "\n",
        "# Matriz de confusión (TRAIN)\n",
        "cm_tr_knn = confusion_matrix(y_train, y_pred_train_knn, labels=knn.classes_)\n",
        "disp_tr_knn = ConfusionMatrixDisplay(confusion_matrix=cm_tr_knn, display_labels=knn.classes_)\n",
        "disp_tr_knn.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - KNN (TRAIN)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC y curvas ROC por clase (TRAIN)\n",
        "y_proba_tr_knn = knn.predict_proba(Xtr)\n",
        "classes_knn = knn.classes_\n",
        "y_train_bin_knn = label_binarize(y_train, classes=classes_knn)\n",
        "\n",
        "roc_auc_train_knn = roc_auc_score(y_train, y_proba_tr_knn, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TRAIN, macro OVR):\", roc_auc_train_knn)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes_knn):\n",
        "    fpr, tpr, _ = roc_curve(y_train_bin_knn[:, i], y_proba_tr_knn[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - KNN (TRAIN)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chcFu_0j7hsK",
      "metadata": {
        "id": "chcFu_0j7hsK"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea6e384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7ea6e384",
        "outputId": "00cabb05-ed84-4ae8-b302-826ab940ffa6"
      },
      "outputs": [],
      "source": [
        "# Predicciones en TEST\n",
        "y_pred_test_knn = knn.predict(Xte)\n",
        "\n",
        "# Evaluación en TEST\n",
        "print(\"--- Evaluación en TEST (KNN) ---\")\n",
        "print(classification_report(y_test, y_pred_test_knn, digits=3))\n",
        "print(\"F1-macro (test):\", f1_score(y_test, y_pred_test_knn, average='macro'))\n",
        "print(\"Accuracy (test):\", accuracy_score(y_test, y_pred_test_knn))\n",
        "\n",
        "# Matriz de confusión (TEST)\n",
        "cm_te_knn = confusion_matrix(y_test, y_pred_test_knn, labels=knn.classes_)\n",
        "disp_te_knn = ConfusionMatrixDisplay(confusion_matrix=cm_te_knn, display_labels=knn.classes_)\n",
        "disp_te_knn.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión - KNN (TEST)\")\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC y curvas ROC por clase (TEST)\n",
        "y_proba_te_knn = knn.predict_proba(Xte)\n",
        "classes_knn = knn.classes_\n",
        "y_test_bin_knn = label_binarize(y_test, classes=classes_knn)\n",
        "\n",
        "roc_auc_test_knn = roc_auc_score(y_test, y_proba_te_knn, multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"\\nROC AUC (TEST, macro OVR):\", roc_auc_test_knn)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, c in enumerate(classes_knn):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin_knn[:, i], y_proba_te_knn[:, i])\n",
        "    plt.plot(fpr, tpr, label=f\"Clase {c} (AUC = {auc(fpr, tpr):.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Curvas ROC por clase - KNN (TEST)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O3UcFLeN7xL1",
      "metadata": {
        "id": "O3UcFLeN7xL1"
      },
      "source": [
        "KNN (k=5, métrica Euclídea) logró macro-F1=0.949 en test con buena generalización. Es un baseline competitivo; sin embargo, Logistic Regression mantiene el mejor equilibrio global (macro-F1=0.956), por lo que la elegimos como modelo final y dejamos KNN como comparación."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3860ea",
      "metadata": {
        "id": "0a3860ea"
      },
      "source": [
        "## Análisis de palabras clave y estrategias\n",
        "\n",
        "A partir de los modelos entrenados, especialmente el de Logistic Regression que mostró un buen rendimiento, podemos identificar las palabras más importantes (con los pesos TF-IDF más altos) que el modelo utilizó para clasificar los textos en cada ODS. Esta información es crucial para entender qué términos son más predictivos de cada categoría y cómo se relacionan con los temas específicos de los ODS 1 (Fin de la Pobreza), 3 (Salud y Bienestar) y 4 (Educación de Calidad).\n",
        "\n",
        "**Identificación de palabras clave:**\n",
        "\n",
        "Podemos extraer los coeficientes del modelo de Regresión Logística para cada clase. Los coeficientes positivos más altos para una clase indican las palabras que son más predictivas de esa clase.\n",
        "\n",
        "**Posibles estrategias para la organización:**\n",
        "\n",
        "La identificación de estas palabras clave es extremadamente útil para la organización porque:\n",
        "\n",
        "1.  **Mejora la comprensión del contenido:** Permite a la organización saber qué temas o términos específicos aparecen con más frecuencia en las opiniones relacionadas con cada ODS.\n",
        "2.  **Optimiza la clasificación manual:** Si aún se realiza alguna clasificación manual, este análisis puede servir como guía para los clasificadores humanos.\n",
        "3.  **Informa la creación de contenido:** La organización puede usar estos hallazgos para enfocar la creación de contenido, comunicaciones o iniciativas en los temas más relevantes para cada ODS.\n",
        "4.  **Permite la detección temprana de tendencias:** Al monitorear la frecuencia de estas palabras clave en nuevos textos, la organización puede identificar rápidamente cambios en las preocupaciones o enfoques de las opiniones relacionadas con los ODS.\n",
        "5.  **Facilita la asignación de recursos:** Entender qué ODS reciben más atención en las opiniones puede ayudar a dirigir recursos de manera más efectiva.\n",
        "\n",
        "**Ejemplo de análisis (a realizar con el código):**\n",
        "\n",
        "Al analizar las palabras con mayor peso para el ODS 1 (Fin de la Pobreza), podríamos encontrar términos como \"pobreza\", \"ingreso\", \"desigualdad\", \"empleo\", \"vivienda\". Para el ODS 3 (Salud y Bienestar), podrían ser \"salud\", \"enfermedad\", \"acceso\", \"servicio\", \"hospital\". Para el ODS 4 (Educación de Calidad), podríamos ver \"educación\", \"escuela\", \"aprendizaje\", \"formación\", \"universidad\".\n",
        "\n",
        "Este análisis permite a la organización ir más allá de la simple clasificación y obtener insights accionables sobre el contenido de las opiniones.\n",
        "\n",
        "A continuación, se presenta el código para obtener las palabras más relevantes para cada clase a partir del modelo de Regresión Logística."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf282a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bf282a7",
        "outputId": "42d96b20-c46e-466e-b78f-1f7344cb9910"
      },
      "outputs": [],
      "source": [
        "# Obtener los coeficientes del modelo de Logistic Regression\n",
        "# El modelo ya fue entrenado en la celda anterior (lr)\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "coefs = lr.coef_\n",
        "classes = lr.classes_\n",
        "\n",
        "# Mostrar las palabras más importantes para cada clase\n",
        "print(\"Palabras más importantes por clase (basado en coeficientes de Logistic Regression):\")\n",
        "for i, class_id in enumerate(classes):\n",
        "    top_n = 10  # Número de palabras a mostrar\n",
        "    top_coef_indices = coefs[i].argsort()[-top_n:][::-1]\n",
        "    top_coef_words = [feature_names[j] for j in top_coef_indices]\n",
        "    print(f\"\\nClase {class_id}:\")\n",
        "    print(top_coef_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1373e7d4",
      "metadata": {
        "id": "1373e7d4"
      },
      "source": [
        "## Exportar datos de prueba con etiquetas predichas\n",
        "\n",
        "Para facilitar la evaluación externa de su modelo, se exportarán los datos del conjunto de prueba (`X_test`) junto con las etiquetas originales (`y_test`) y las etiquetas predichas por el modelo de Regresión Logística (`y_pred_test_lr`) a un archivo Excel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2bbd3dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2bbd3dd",
        "outputId": "670dee5f-2026-4ad0-adf0-d7e931bb36bb"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame con los datos de prueba, etiquetas originales y predichas\n",
        "test_results_df = pd.DataFrame({\n",
        "    'texto': X_test, # Usar los textos originales si están disponibles, o los preprocesados si no\n",
        "    'etiqueta_original': y_test,\n",
        "    'etiqueta_predicha_LR': y_pred_test_lr\n",
        "})\n",
        "# Exportar a Excel\n",
        "test_results_df.to_excel(\"resultados_prediccion_LR_test.xlsx\", index=False)\n",
        "\n",
        "print(\"Datos de prueba con etiquetas originales y predichas exportados a 'resultados_prediccion_LR_test.xlsx'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab01-bi",
      "language": "python",
      "name": "lab01-bi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
